{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l10Ly_j8iM5T"
      },
      "outputs": [],
      "source": [
        "# Section 5.3\n",
        "# Contains the extraction process of 4 features used in Void system\n",
        "# feature extraction\n",
        "\n",
        "# !pip install pydub\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wav\n",
        "import scipy.signal as ssig\n",
        "import scipy.stats as stats\n",
        "from scipy.signal import find_peaks\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import librosa\n",
        "import librosa\n",
        "from sklearn import svm\n",
        "from sklearn import svm\n",
        "import pickle\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def _stft(y):\n",
        "    n_fft, hop_length, _ = _stft_parameters()\n",
        "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "\n",
        "def _stft_parameters():\n",
        "    # n_fft = (num_freq - 1) * 2\n",
        "    n_fft = 2048\n",
        "    hop_length = 128\n",
        "    # hop_length = int(frame_shift_ms / 1000 * sample_rate)\n",
        "    # win_length = int(frame_length_ms / 1000 * sample_rate)\n",
        "    win_length = 512\n",
        "    return n_fft, hop_length, win_length\n",
        "\n",
        "\n",
        "def LinearityDegreeFeatures(power_normal):\n",
        "    # Calculate signal power linearity degree features\n",
        "    # input: power_normal\n",
        "    # output: FV_LDF\n",
        "\n",
        "    # Normalize power_vec as power_normal:\n",
        "    #power_normal = power_vec / np.sum(power_vec)\n",
        "    # From power_normal, calculate cumulative distribution of spectral power power_cdf:\n",
        "    power_cdf = np.cumsum(power_normal)\n",
        "    # Compute the correlation coefficients of power_cdf and store the results as rho:\n",
        "    pearson_co = stats.pearsonr(power_cdf, np.arange(power_cdf.size))\n",
        "    rho = pearson_co[0]\n",
        "    #print(\"rho =\", rho)\n",
        "    # Compute the quadratic coefficients of power_cdf and store the results as q:\n",
        "    #x_values = np.arange(0, 8+8/(power_cdf.size-1), 8/(power_cdf.size-1))\n",
        "    x_values = np.arange(0, 8+7/(power_cdf.size-1), 8/(power_cdf.size-1))\n",
        "    #parameter_2 = np.polyfit(x_values, power_cdf, 2)\n",
        "    parameter_2 = np.polyfit(power_cdf, x_values, 2)\n",
        "    q = parameter_2[0]\n",
        "    #print(\"q =\", q)\n",
        "    # Form rho and q as FV_LDF:\n",
        "    FV_LDF = np.array([rho, q])\n",
        " \n",
        "    # Plot power_cdf and its estimation if necessary:\n",
        "    plt.rc('text', usetex=True)\n",
        "    plt.rc('font', family='serif')\n",
        "    plt.figure()\n",
        "    plt.plot(x_values, power_cdf, color='red', marker='d', label=r'$\\textbf{pow}_\\textbf{cdf}$')\n",
        "    plt.plot(x_values, np.polyval(parameter_2, x_values), color='blue',\n",
        "        marker='o', label=r'$\\textbf{fitting curve to pow}_\\textbf{cdf}$')\n",
        "    plt.xlabel(r'\\textbf{Frequency (kHz)}', fontsize=16)\n",
        "    plt.ylabel(r'$\\textbf{pow}_\\textbf{cdf}$', fontsize=16)\n",
        "    # The coordinate of starting point and end point of the arrow should be chosen manually:\n",
        "    plt.annotate('rho = %.3f \\n q = %.3f' % (rho, q), xy=(0.4, np.polyval(parameter_2, 0.4)-0.1),\n",
        "        xytext=(1, 0.3), arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3\"), fontsize=12)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Return power_cdf for plotting figures:\n",
        "    return power_cdf, FV_LDF\n",
        "\n",
        "\n",
        "def HighPowerFrequencyFeatures(FV_LFP, omega):\n",
        "    # Calculate high power frequency\n",
        "    # input: FV_LFP, omega\n",
        "    # output: FV_HPF\n",
        "\n",
        "    # 1. Find peaks from FV_LFP (returns the indices of found peaks):\n",
        "    peaks_idx, _ = find_peaks(FV_LFP, height=0)\n",
        "    # Obtain corresponding values of the peaks:\n",
        "    peaks_val = FV_LFP[peaks_idx]\n",
        "    # 2. Compute the threshold of selecting peaks using omega:\n",
        "    T_peak = omega * max(peaks_val)\n",
        "    # 3. Remove peaks lower than T_peak (insignificant peaks):\n",
        "    peaks_idx = peaks_idx[np.where(peaks_val >= T_peak)]\n",
        "    peaks_val = FV_LFP[peaks_idx]\n",
        "    # 4. Obtain the number of remaining peaks:\n",
        "    N_peak = peaks_idx.size\n",
        "    # 5. Compute the mean of the locations of remaining peaks:\n",
        "    mu_peak = peaks_idx.mean()\n",
        "    # 6. Compute the standard deviation of the locations of remaining peaks:\n",
        "    sigma_peak = np.std(peaks_idx)\n",
        "    # 7. Use a 6-order polynomial to fit FV_LFP and take first 32 estimatied values as P_est:\n",
        "    parameter_6 = np.polyfit(np.arange(FV_LFP.size), FV_LFP, 6)\n",
        "    value_est = np.polyval(parameter_6, np.arange(FV_LFP.size))\n",
        "    '''\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(FV_LFP.size), FV_LFP, 'r')\n",
        "    plt.plot(np.arange(FV_LFP.size), value_est, 'b')\n",
        "    plt.show()\n",
        "    '''\n",
        "    P_est = value_est[0:32]\n",
        "    # Construct FV_HPF (insert N_peak, mu_peak and sigma_peak in fornt of P_est):\n",
        "    FV_HPF = np.insert(P_est, 0, [N_peak, mu_peak, sigma_peak])\n",
        "    return FV_HPF\n",
        "\n",
        "\n",
        "def lpc_to_lpcc(lpc):\n",
        "    # Based on given LPC, calculate LPCC:\n",
        "    lpcc = []\n",
        "    order = lpc.size - 1\n",
        "    # The 1st element equals ln(order):\n",
        "    lpcc.append(math.log(order))\n",
        "    lpcc.append(lpc[1])\n",
        "    for i in range(2, order+1):\n",
        "        sum_1 = 0\n",
        "        for j in range(1, i):\n",
        "            sum_1 += j / i * lpc[i-j-1] * lpcc[j]\n",
        "        c = -lpc[i-1] + sum_1\n",
        "        lpcc.append(c)\n",
        "    return lpcc[1:13]\n",
        "\n",
        "\n",
        "def extract_lpcc(wav_path, order):\n",
        "    y, _ = librosa.load(wav_path, sr=16000)\n",
        "    lpc = librosa.lpc(y,order=order)\n",
        "    lpcc = np.array(lpc_to_lpcc(lpc))\n",
        "    return lpcc\n",
        "\n",
        "\n",
        "# https://www.cnblogs.com/klchang/p/9280509.html\n",
        "def calc_stft(signal, sample_rate=16000, frame_size=512, frame_stride=128, winfunc=np.hamming, NFFT=2048):\n",
        "\n",
        "    # Calculate the number of frames from the signal\n",
        "    signal_length = len(signal)\n",
        "    frame_step = frame_stride\n",
        "    num_frames = 1 + int(np.ceil(float(np.abs(signal_length - frame_size)) / frame_step))\n",
        "    # zero padding\n",
        "    pad_signal_length = num_frames * frame_step + frame_size\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    # Pad signal to make sure that all frames have equal number of samples\n",
        "    # without truncating any samples from the original signal\n",
        "    pad_signal = np.append(signal, z)\n",
        "\n",
        "    # Slice the signal into frames from indices\n",
        "    indices = np.tile(np.arange(0, frame_size), (num_frames, 1)) + \\\n",
        "            np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_size, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    # Get windowed frames\n",
        "    frames *= winfunc(frame_size)\n",
        "    # Compute the one-dimensional n-point discrete Fourier Transform(DFT) of\n",
        "    # a real-valued array by means of an efficient algorithm called Fast Fourier Transform (FFT)\n",
        "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
        "    # Compute power spectrum\n",
        "    pow_frames = (1.0 / NFFT) * ((mag_frames) ** 2)\n",
        "    '''\n",
        "    # Calculate the number of frames from the signal\n",
        "    frame_length = frame_size * sample_rate\n",
        "    frame_step = frame_stride * sample_rate\n",
        "    signal_length = len(signal)\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    num_frames = 1 + int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))\n",
        "    # zero padding\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_signal_length - signal_length))\n",
        "    # Pad signal to make sure that all frames have equal number of samples\n",
        "    # without truncating any samples from the original signal\n",
        "    pad_signal = np.append(signal, z)\n",
        "\n",
        "    # Slice the signal into frames from indices\n",
        "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) +\n",
        "        np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
        "    # Get windowed frames\n",
        "    frames *= winfunc(frame_length)\n",
        "    # Compute the one-dimensional n-point discrete Fourier Transform(DFT) of\n",
        "    # a real-valued array by means of an efficient algorithm called Fast Fourier Transform (FFT)\n",
        "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
        "    # Compute power spectrum\n",
        "    pow_frames = (1.0 / NFFT) * ((mag_frames) ** 2)\n",
        "    '''\n",
        "    return pow_frames\n",
        "\n",
        "\n",
        "def load_audio_file(file_path):\n",
        "    # Check the file extension\n",
        "    file_ext = os.path.splitext(file_path)[1]\n",
        "    if file_ext.lower() == '.mp3':\n",
        "        # Load MP3 file\n",
        "        audio = AudioSegment.from_mp3(file_path)\n",
        "        # Construct the output file path by replacing the extension with '.wav'\n",
        "        output_file_path = os.path.splitext(file_path)[0] + '.wav'\n",
        "        # Convert MP3 to WAV and save the file\n",
        "        audio.export(output_file_path, format=\"wav\")\n",
        "    elif file_ext.lower() == '.wav':\n",
        "        # Load WAV file\n",
        "        audio = AudioSegment.from_wav(file_path)\n",
        "        output_file_path = file_path  # No need to save if it's already in WAV format\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only MP3 and WAV are supported.\")\n",
        "\n",
        "    return output_file_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prUW0iO884fw",
        "outputId": "6fa500d6-a203-43ce-92bf-5bb7c1833ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature extraction for eval has not been done. Extract Void features...\n",
            "Feature extraction FINISHED!\n"
          ]
        }
      ],
      "source": [
        "dataset_labels = ['eval']\n",
        "\n",
        "for dataset in dataset_labels:\n",
        "    feature_file = os.path.join(os.getcwd(), 'feature_label_{}.npy'.format(dataset))\n",
        "\n",
        "    # If all the features and labels are extracted and stored into './feature_label.txt', then directly load this file;\n",
        "    # Otherwise, generate this file first:\n",
        "    if os.path.isfile(feature_file):\n",
        "        print(\"The features has already been extracted!\")\n",
        "    else:\n",
        "        print('Feature extraction for ' + dataset + ' has not been done. Extract Void features...')\n",
        "        # PREPARATION:\n",
        "        # Path to data:\n",
        "        data_path = os.path.join(os.getcwd(),'audio',dataset)\n",
        "        # Protocol of data:\n",
        "        protocol = os.path.join(os.getcwd(),'ASVspoof2017_V2_eval.trl.txt')\n",
        "        # Load the filenames and corresponding labels:\n",
        "        fp = open(protocol)\n",
        "        lines = fp.readlines()\n",
        "        name_seq = []\n",
        "        label_seq = []\n",
        "        for line in lines:\n",
        "            str_list = line.split()\n",
        "            name_seq.append(str_list[0])\n",
        "            label_seq.append(str_list[1])\n",
        "\n",
        "        # Initialize parameters:\n",
        "        W = 14\n",
        "        # Peak selection threshold:\n",
        "        omega = 0.3\n",
        "        # Number of points in each signal segment (window size):\n",
        "        nperseg = 512\n",
        "        # Hop length of the window is 25% nperseg (with 75% overlap):\n",
        "        noverlap = 512-128\n",
        "        # Number of FFT points:\n",
        "        nfft = 2048\n",
        "        # Calculate the number of segments k in S_pow:\n",
        "        k = int((nfft/2 + 1) / W)\n",
        "\n",
        "        # Create an empty Numpy array to store extracted features as well as corresponding labels:\n",
        "        fl = np.zeros((len(name_seq), 98))\n",
        "\n",
        "        for name_idx in np.arange(len(name_seq)):\n",
        "            #Obtain the name of current file:\n",
        "            filename = name_seq[name_idx]\n",
        "            # Obtain the label of current file:\n",
        "            label = label_seq[name_idx]\n",
        "\n",
        "            # ------ Stage 1: Signal transformation ------\n",
        "            # Read the input signal:\n",
        "            output_file_path=load_audio_file(os.path.join(data_path, filename))\n",
        "            signal, _ = librosa.load(output_file_path, sr=16000)\n",
        "\n",
        "            # Compute STFT for the input signal:\n",
        "            sig_stft = _stft(signal)\n",
        "\n",
        "            # Compute S_pow from STFT:\n",
        "            S_pow = np.sum(np.abs(sig_stft)**2/nfft, axis=1)\n",
        "\n",
        "            # ------ Stage 2: Feature Extraction ------\n",
        "            # Calculate the sum of power in each segment (in total k segments):\n",
        "            power_vec = np.zeros(k)\n",
        "            for i in np.arange(k):\n",
        "                power_vec[i] = np.sum(S_pow[i*W:(i+1)*W])\n",
        "            # Normalize power_vec as power_normal:\n",
        "            power_normal = power_vec / np.sum(power_vec)\n",
        "\n",
        "            # Feature 1: FV_LFP - low frequencies power features\n",
        "            FV_LFP = power_normal[0:48] * 100\n",
        "            #print(FV_LFP)\n",
        "\n",
        "            # Feature 2: FV_LDF - signal power linearity degree features\n",
        "            _, FV_LDF = LinearityDegreeFeatures(power_normal)\n",
        "            #FV_LDF = np.zeros(2)\n",
        "\n",
        "            # Feature 3: FV_HPF - high power frequency features\n",
        "            FV_HPF = HighPowerFrequencyFeatures(FV_LFP, omega)\n",
        "            #FV_HPF = np.zeros(35)\n",
        "\n",
        "            # Feature 4: FV_LPC - linear prediction cesptrum coefficients\n",
        "            FV_LPC = extract_lpcc(os.path.join(data_path, filename), 12)\n",
        "            #FV_LPC = np.zeros(12)\n",
        "\n",
        "            # ------ Stage 3: Attack Detection ------\n",
        "            # Normalize each sub-feature:\n",
        "            '''\n",
        "            mean_LFP = np.mean(FV_LFP)\n",
        "            FV_LFP = (FV_LFP - mean_LFP) / (FV_LFP.max() - FV_LFP.min())\n",
        "            mean_LDF = np.mean(FV_LDF)\n",
        "            FV_LDF = (FV_LDF - mean_LDF) / (FV_LDF.max() - FV_LDF.min())\n",
        "            mean_HPF = np.mean(FV_HPF)\n",
        "            FV_HPF = (FV_HPF - mean_HPF) / (FV_HPF.max() - FV_HPF.min())\n",
        "            mean_LPC = np.mean(FV_LPC)\n",
        "            FV_LPC = (FV_LPC - mean_LPC) / (FV_LPC.max() - FV_LPC.min())\n",
        "            '''\n",
        "            # Construct the final feature of length 97 (= 2 + 35 + 12 + 48):\n",
        "            FV_Void = np.concatenate((FV_LDF, FV_HPF, FV_LPC, FV_LFP))\n",
        "            #FV_Void = np.concatenate((FV_LDF, FV_LPC))\n",
        "            '''\n",
        "            print(\"Extracted Void feature for {} is:\".format(filename))\n",
        "            print(FV_Void)\n",
        "            print(\"--------------------------------------------\")\n",
        "            '''\n",
        "\n",
        "            if label == 'genuine':\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 0\n",
        "            fl[name_idx, 0:97] = FV_Void\n",
        "            fl[name_idx, 97] = label\n",
        "        np.save(feature_file, fl)\n",
        "\n",
        "print(\"Feature extraction FINISHED!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vzE1-hM_kSy"
      },
      "outputs": [],
      "source": [
        "def audio_label(s):\n",
        "    it = {b'genuine':1, b's/////////////////////poof':0}\n",
        "    return it[s]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i65Dg2xWALrv",
        "outputId": "ad1b5f3a-cb9a-485d-b6a3-c2d5eb898c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on EVALUATION SET:\n",
            "predict, actual: 0.525418295544118 [1.]\n",
            "predict, actual: 0.7776566384841299 [1.]\n",
            "predict, actual: 0.41728831386440346 [1.]\n",
            "predict, actual: 0.45483333005977916 [0.]\n",
            "predict, actual: 0.5910411211363287 [0.]\n",
            "predict, actual: 0.7022448416281751 [0.]\n",
            "predict, actual: 0.32840359087963494 [0.]\n"
          ]
        }
      ],
      "source": [
        "# Import evaluation data for testing:\n",
        "file_eval = os.path.join(os.getcwd(),'feature_labels','feature_label_eval.npy')\n",
        "# If all the features and labels are extracted and stored into './feature_label.txt', then directly load this file;\n",
        "# Otherwise, generate this file first:\n",
        "if os.path.isfile(file_eval):\n",
        "    # Load the extracted features and corresponding labels:\n",
        "    data_eval = np.load(file_eval)\n",
        "else:\n",
        "    print('Feature extraction has not been done. Please extract Void features using data_preparation.py!')\n",
        "# Load the Void features and corresponding labels:\n",
        "x_eval, y_eval = np.split(data_eval, indices_or_sections=(97,), axis=1)\n",
        "\n",
        "# Load the the SVM classifier model:\n",
        "file_model = os.path.join(os.getcwd(),'svm.pkl')\n",
        "if os.path.isfile(file_model):\n",
        "    # Load the extracted features and corresponding labels:\n",
        "    with open(file_model, 'rb') as f:\n",
        "      classifier=pickle.load(f)\n",
        "else:\n",
        "    print('Feature extraction has not been done. Please extract Void features using data_preparation.py!')\n",
        "\n",
        "# Prediction result of SVM classifier on EVALUATION set of ASVspoof 2017 v2 dataset:\n",
        "print(\"Results on EVALUATION SET:\")\n",
        "result_pred = classifier.predict(x_eval)\n",
        "for i in np.arange(y_eval.size):\n",
        "        # The i-th predicted label:\n",
        "        label_pred = result_pred[i]\n",
        "        # The actual label for i-th sample:\n",
        "        label_actual = y_eval[i]\n",
        "\n",
        "        print(\"predict, actual:\", label_pred, label_actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc0rIDQXGVFL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
